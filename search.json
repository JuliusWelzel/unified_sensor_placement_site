[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "On the transferability and accessibility of human movement data",
    "section": "",
    "text": "Human motion capture is a suite of technologies and techniques to record a motion modality (i.e., position, speed, or acceleration) of the human moving parts and their environment, with extensive uses in movement science, rehabilitation, sports, and entertainment. However, the heterogeneity of the recorded modality and the spatial and temporal resolutions of the recordings make the utility and interpretability of the motion capture recordings challenging. [some examples of the importance and use of such helpful interpretability].\nMotion capture is a general term for acquiring a motion-related physical quantity (i.e., motion modality), such as position, speed, acceleration, etc. [talk about the fundamental differences between having each quantity.]\nTechnologies related to motion capture mainly record one of the physical quantities, while the rest could, in theory, be driven by differentiation and integration coupled with some constraints. [talk about different techs, passive active marker-based, IMUs, ToF and dot projection, video cameras, and deep learning]\nLimitations of each method for motion capture manifest in the interpretability and transferability of the data from one modality to another. [brief discussions about the limitations]. A solution to address these limitations is an adequate and precise annotation of the features affecting the motion capture interpretation quality.\nHere we 1. briefly describe the main features of each modality. 2. We then discuss the annotations required for each modality that would adequately help with the interpretability of the motion capture data. 3. We finally introduce a set of best practices in defining coordinate systems and sensor placement schemes that would provide a framework for the interpretability of the motion capture data from one modality to another."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "On the transferability and accessibility of human movement data",
    "section": "",
    "text": "Human motion capture is a suite of technologies and techniques to record a motion modality (i.e., position, speed, or acceleration) of the human moving parts and their environment, with extensive uses in movement science, rehabilitation, sports, and entertainment. However, the heterogeneity of the recorded modality and the spatial and temporal resolutions of the recordings make the utility and interpretability of the motion capture recordings challenging. [some examples of the importance and use of such helpful interpretability].\nMotion capture is a general term for acquiring a motion-related physical quantity (i.e., motion modality), such as position, speed, acceleration, etc. [talk about the fundamental differences between having each quantity.]\nTechnologies related to motion capture mainly record one of the physical quantities, while the rest could, in theory, be driven by differentiation and integration coupled with some constraints. [talk about different techs, passive active marker-based, IMUs, ToF and dot projection, video cameras, and deep learning]\nLimitations of each method for motion capture manifest in the interpretability and transferability of the data from one modality to another. [brief discussions about the limitations]. A solution to address these limitations is an adequate and precise annotation of the features affecting the motion capture interpretation quality.\nHere we 1. briefly describe the main features of each modality. 2. We then discuss the annotations required for each modality that would adequately help with the interpretability of the motion capture data. 3. We finally introduce a set of best practices in defining coordinate systems and sensor placement schemes that would provide a framework for the interpretability of the motion capture data from one modality to another."
  },
  {
    "objectID": "index.html#types-of-motion-capture",
    "href": "index.html#types-of-motion-capture",
    "title": "On the transferability and accessibility of human movement data",
    "section": "Types of motion capture",
    "text": "Types of motion capture\nIn the following chapter we will introduce three main types of motion capture systems, what type of data they record and the limits of transferability between them. We will also include how current specifications of sensor placements are done.\nOptical Motion Capture (OMC): Marker based optical motion capture systems utilize multiple cameras to track the movement of reflective markers placed on a subject’s body or objects. These markers reflect light emitted by the cameras, allowing the system to triangulate their positions in three-dimensional space. The cameras record the positions of these markers at high frame rates, typically capturing data on marker positions (POS) and, optionally, orientation (ORNT). Additionally, velocity (VEL), acceleration (ACCEL), and angular acceleration (ANGACCEL) data can be derived from the marker positions over time. The placement of markers should usually define marker type, size, and shape, along with their specific placement on anatomical landmarks or reference points, often including joints, limb segments, and other relevant locations.\nInertial Measurement Units (IMUs): Inertial measurement units consist of small sensors, including accelerometers, gyroscopes, and sometimes magnetometers, attached to a subject’s body. IMUs measure changes in acceleration, angular velocity, and magnetic field strength, allowing them to record acceleration (ACCEL), angular acceleration (ANGACCEL), velocity (VEL), and orientation (ORNT). IMUs are compact and versatile, making them suitable for wearable applications, such as sports performance analysis and motion tracking in remote or outdoor environments. Positioning of the IMU on the human body should contain information about the location and orientation. The location often follows free form text and the orientation is described using photos or some kind of orientation in relation to the body part it is attached to.\nMarkerless Motion Capture: Markerless motion capture systems rely on algorithms to track a subject’s movements without the need for physical markers. These systems use cameras to capture video footage of the subject, and then some form of software processes the images to extract data on position (POS), orientation (ORNT), and sometimes velocity (VEL) and acceleration (ACCEL). Markerless motion capture is advantageous for its non-invasive nature and ability to capture natural movement, making it popular in the fields of entertainment, biomechanics, and human-computer interaction. The definition of the tracked points is often closely bound to the software and which points it allows to be tracked."
  },
  {
    "objectID": "index.html#definitions",
    "href": "index.html#definitions",
    "title": "On the transferability and accessibility of human movement data",
    "section": "Definitions",
    "text": "Definitions\nSpace [in BIDS terms] BIDS defines ``space’’ as an artificial frame of reference, created to describe different anatomies in a unifying manner (see Appendix VIII). However, data collected in studies of physical or virtual motion usually have a reference frame that is anchored to the physical lab space or the virtual environment.\nReference frame A reference frame, or a frame of reference is an abstract coordinate system whose origin, orientation, and scale are specified by a set of reference points (Kovalevsky & Mueller, 1989). Here we interpret the concept of reference frame as a broad description of the type of the space, or the context that the data is associated with. It relates to whether the space itself is fixed or moving (global or local reference frame), or the identity of the object it moves with. For example, an anatomical reference frame is fixed to the body and moves when the body itself moves through space.\nCoordinate system Examples : Cartesian coordinates, polar coordinates, and spherical coordinates. A coordinate system is fully described by (1) the origin, (2) the interpretation of the axes, and (3) the units.\n[in BIDS terms] A coordinate system in BIDS comprises of the information about (1) the origin relative to which the coordinate is expressed, (2) the interpretation of the three axes, and (3) the units in which the numbers are expressed\nCoordinate systems Motion data can be expressed within different coordinate systems associated with different frames of reference. The type of reference frame that requires the most detailed description is the anatomical, body-based reference frames.\nReference frames can have a hierarchical structure where one reference frame is nested within another. For example, the position of the torso can be expressed in a coordinate system within the room reference frame, the arm position relative to the torso, and the hand position relative to the arm. In biomechanics …\nWe refer to the reference frame that is at the top level of this hierarchy as the “global” reference frame. The global reference frame can be associated with the space through which the entire body moves, allowing the location of the person to be expressed as a position within that space. This representation is useful in scenarios where the location of the person in space is relevant rather than their posture or limb motion. For example, in spatial cognition research …"
  },
  {
    "objectID": "index.html#anatomical-coordinate-system-for-each-rigid-body-part-julius",
    "href": "index.html#anatomical-coordinate-system-for-each-rigid-body-part-julius",
    "title": "On the transferability and accessibility of human movement data",
    "section": "Anatomical coordinate system for each rigid body part (Julius)",
    "text": "Anatomical coordinate system for each rigid body part (Julius)\nAxis per body part are defined in the anatomical landmark table. The table includes the name of the body part, the axis, and the direction of the axis. The axis and direction is defined using the anatomical landmarks, with the limits of the axis ranging from 0 to 100% of the distance between the landmarks."
  },
  {
    "objectID": "index.html#unified-placement-scheme",
    "href": "index.html#unified-placement-scheme",
    "title": "On the transferability and accessibility of human movement data",
    "section": "Unified placement scheme",
    "text": "Unified placement scheme\nThe most common types of motion data are acceleration, angular acceleration, joint angles, magnetic field strength, orientation and position. Each type has different requirements for sensor placement. We want to present a way of encoding the marker location and orientation so that it can be unified across different data sets. …"
  },
  {
    "objectID": "authors.html",
    "href": "authors.html",
    "title": "Authors",
    "section": "",
    "text": "Sein is investigating human spatial cognition using mobile EEG at the Berlin Mobile Brain-Body Imaging Lab & Doellerlab. She is a dedicated Open Science enthusiast!"
  },
  {
    "objectID": "authors.html#sein-jeung",
    "href": "authors.html#sein-jeung",
    "title": "Authors",
    "section": "",
    "text": "Sein is investigating human spatial cognition using mobile EEG at the Berlin Mobile Brain-Body Imaging Lab & Doellerlab. She is a dedicated Open Science enthusiast!"
  },
  {
    "objectID": "authors.html#julius-welzel",
    "href": "authors.html#julius-welzel",
    "title": "Authors",
    "section": "Julius Welzel",
    "text": "Julius Welzel\nJulius has completed his masters in 2019 in Cognitive Neuropsychology in Oldenburg, Germany and is still pursuing his PhD in Kiel, Germany where he started building a Open Science EEG lab based in the deparment of Neurology. He has a daughter which you can meet at conferences or in one of his many Zoom calls."
  },
  {
    "objectID": "authors.html#yahya-shirazi",
    "href": "authors.html#yahya-shirazi",
    "title": "Authors",
    "section": "Yahya Shirazi",
    "text": "Yahya Shirazi\nYahya is an Assistant Project Scientist at the Swartz center for Computational Neuroscience working hard to make the MOBI world a better place."
  },
  {
    "objectID": "anatomical_table.html",
    "href": "anatomical_table.html",
    "title": "Human Body Segmentation",
    "section": "",
    "text": "Human Body Segmentation\n\n\n\nModified Hanavan model, see Hatze 1980\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHanavan body part\nHED label\nHED description\nAnatomical Description\nFiducials (fiducial locations)\nCoordinate system\nExample IMU\nExample Mocap\n\n\n\n\n1\nHead\nThe upper part of the human body, or the front or upper part of the body of an animal, typically separated from the rest of the body by a neck, and containing the brain, mouth, and sense organs.\nThe structure superior to the neck, encasing the brain, eyes, ears, nose, and mouth. It is demarcated by the skull, which separates the head from the neck at the base of the skull.\n1. Nasion (100,0,0),  2. Inion (0,0,0),  Helix-Tragus Junction (HJ)  3. LHJ (0,0,0)  4. RHJ (0,100,0)  5. Vertex (0,0,100)  6. Midpoint between of mastoid processes (0,0,0)\nX: Left ear → right ear Y: Inion → Nasion Z: Right-hand ruleLeft Vertex-&gt;Neck (limits. C2 and Vertex)\n1.(-50,0,0) bp.(x,y,z) HED:\n1. (40,-50,-50) 2. (40,50,-50) 3. (-40,-50,-50) 4. (40,-50,-50)\n\n\n?\nNeck\n[The part of the body connecting the head to the torso, containing the cervical spine and vital pathways of nerves, blood vessels, and the airway.]\nThe anatomical region bounded by the base of the skull, and the clavicles inferiorly, containing vital structures such as the cervical vertebrae, spinal cord, carotid arteries, and trachea.\n1. Midpoint between of mastoid processes  2.C7 verterbra  3. Suprasternal Notch (Jugular Notch)\nX: right-hand rule (limits?) Y: C7 → Suprasternal notch Z: Suprasternal notch → Mastoid midpoint\n\n\n\n\n2\nTorso (Thorax)\nThe body excluding the head and neck and limbs.\nThe upper part of the torso, extending from the base of the neck to the diaphragm. It’s framed by the rib cage, which includes the ribs, sternum, and thoracic vertebrae. The thorax houses vital organs such as the heart and lungs.\n1. Acromion process Left → Right  2. Vertebra Prominens (C7), 3. Xiphoid Process\nX: Left → Right acromion process Y: Vertebra Prominens → Xiphoid Process Z: Right-hand rule (limits, Xiphoid and C7)\n1. (50,-40,0) 2. (-50, 30, 0)\n1. (50,-40,0) 2. (0, -50, -50) 3. (0, -50, 50) 4. ? 5. ? 6. ? 7. ?\n\n\n3\nTorso (Abdomen)\nThe body excluding the head and neck and limbs.\nThe lower part of the torso, situated between the thorax and the pelvis. It is bounded superiorly by the diaphragm and inferiorly by the pelvic girdle. The abdomen contains important digestive, urinary, and reproductive organs, and is supported by various abdominal muscles.\n1. Umbilicus (Navel),  2. Anterior Superior Iliac Spine (ASIS)  3. Posterior Superior Iliac Spine (PSIS)  4. Xiphoid Process \nX: Left → Right ASIS Y: Right-hand rule, (limits, ASIS and PSIS) Z: Umbilicus → Xiphoid Process\n\n\n\n\n4\n(Right, Hand)\nThe distal portion of the upper extremity. It consists of the carpus, metacarpus, and digits.\nThe terminal part of the forearm, beginning at the wrist joint (where the radius and ulna meet the carpal bones) and extending to the fingertips, including the carpus, metacarpus, and phalanges.\n1. Radial Styloid Process (RSP) 2. Ulnar Styloid Process (USP)  3.Third Metacarpophalangeal Joint (MCP): The knuckle of the middle finger\nX: RSP → USP Y: Right hand rule (limits, ?) Z: MCP → Midline RSP-USP\n\n\n\n\n5\n(Left, Hand)\nThe distal portion of the upper extremity. It consists of the carpus, metacarpus, and digits.\nThe terminal part of the forearm, beginning at the wrist joint (where the radius and ulna meet the carpal bones) and extending to the fingertips, including the carpus, metacarpus, and phalanges.\n1. Radial Styloid Process (RSP) 2. Ulnar Styloid Process (USP)  3.Third Metacarpophalangeal Joint (MCP): The knuckle of the middle finger\nX: USP → RSP Y: Right hand rule (limits, wrist depth, from dorsal to palmar surface at the midpoint RSP-USP?) Z: MCP → Midline RSP-USP\n\n\n\n\n6\n(Right, Upper-arm)\nPortion of arm between shoulder and elbow.\nThe segment between the shoulder and elbow, outlined by the humerus bone. It starts at the glenohumeral joint and ends at the elbow joint where the humerus meets the radius and ulna.\n1. Acromion  2. Medial Humerus Epicondyle (MHE)  3. Lateral Humerus Epicondyle (LHE)\nX: MHE → LHE Y: Right-hand rule (limits, most prominent point of the olecranon process at the back of the elbow (posteriorly) to the least prominent point of the cubital fossa (anteriorly)?) Z: Perpendicular line from MHE-LHE → Acromion\n? ?\n\n\n\n7\n(Left, Upper-arm)\nPortion of arm between shoulder and elbow.\nThe segment between the shoulder and elbow, outlined by the humerus bone. It starts at the glenohumeral joint and ends at the elbow joint where the humerus meets the radius and ulna.\n1. Acromion  2. Medial Humerus Epicondyle (MHE)  3. Lateral Humerus Epicondyle (LHE)\nX: MHE → LHE Y: Right-hand rule (limits, most prominent point of the olecranon process at the back of the elbow (posteriorly) to the least prominent point of the cubital fossa (anteriorly)?) Z: Perpendicular line from MHE-LHE → Acromion\n\n\n\n\n8\n(Right, Forearm)\nLower part of the arm between the elbow and wrist.\nExtends from the elbow to the wrist, demarcated by the radius and ulna. Begins at the elbow joint and ends at the wrist joint.\n1. RSP 2. USP 3. LHE\nX: RSP → USP Y: Right-hand rule (limits,most prominent point of the olecranon process at the back of the elbow (posteriorly) to the least prominent point of the cubital fossa (anteriorly)?) Z: perp of RSP-USP → LHE\n\n\n\n\n9\n(Left, Forearm)\nLower part of the arm between the elbow and wrist.\nExtends from the elbow to the wrist, demarcated by the radius and ulna. Begins at the elbow joint and ends at the wrist joint.\n1. RSP 2. USP 3. LHE\nX: USP → RSP Y: Right-hand rule (limits,most prominent point of the olecranon process at the back of the elbow (posteriorly) to the least prominent point of the cubital fossa (anteriorly)?) Z: perp of RSP-USP → LHE\n\n\n\n\n10\n(Right, Thigh)\nUpper part of the leg between hip and knee.\nThe part of the lower limb extending from the hip to the knee, primarily composed of the femur. It starts at the hip joint (where the femur connects with the pelvic girdle) and ends at the knee joint.\n1. Greater Trochanter  2. Femur Medial Epicondyle (FME)  3. Femur Lateral Epicondyle (FLE)\nX: FME → FLE Y: Right-hand rule (limits,least prominent point of the popliteal fossa at the back of the knee joint (posteriorly) to the most prominent point of the patellar bone while standing (anteriorly)?) Z: perp of FME-FLE → Greater Trochanter\n1. (0, 50, 0)\n1. (0, 50, 0)\n\n\n11\n(Left, Thigh)\nUpper part of the leg between hip and knee.\nThe part of the lower limb extending from the hip to the knee, primarily composed of the femur. It starts at the hip joint (where the femur connects with the pelvic girdle) and ends at the knee joint.\n1. Greater Trochanter  2. Femur Medial Epicondyle (FME) 3. Femur Lateral Epicondyle (FLE)\nX: FLE → FME Y: Right-hand rule (limits, least prominent point of the popliteal fossa at the back of the knee joint (posteriorly) to the most prominent point of the patellar bone while standing (anteriorly)?) Z: perp of FME-FLE → Greater Trochanter\n1. (0, 50, 0)\n1. (0, 50, 0)\n\n\n12\nRight, Calf & Shin?\n?\nCalf: The posterior segment of the lower leg, from the knee to the ankle. The calf muscles (gastrocnemius and soleus) overlay the tibia and fibula, starting below the knee joint and extending to the ankle. Shin: The anterior part of the lower leg, starting just below the knee joint and extending to the ankle. It primarily involves the tibia.\n1. Lateral Malleolus (LM) 2. Medial Malleolus (MM) 3. Tibial Tuberosity\nX: MM → LM Y: Right-hand rule (limits, least prominent point of the popliteal fossa at the back of the knee joint (posteriorly) to the most prominent point of the patellar bone while standing (anteriorly)?) Z: perp of MM-LM → Tibial Tuberosity\n1. (-40, -50, 0) 2. (40, 50, 0)\n1. (-40, -50, 0)\n\n\n13\nLeft, Calf & Shin?\n?\n\n1. Lateral Malleolus (LM) 2. Medial Malleolus (MM) 3. Tibial Tuberosity\nX: LM → MM Y: Right-hand rule (limits,least prominent point of the popliteal fossa at the back of the knee joint (posteriorly) to the most prominent point of the patellar bone while standing (anteriorly)?) Z: perp of MM-LM → Tibial Tuberosity\n1. (-40, -50, 0) 2. (40, 50, 0)\n1. (-40, -50, 0)\n\n\n14\n(Right, Foot)\nThe structure found below the ankle joint required for locomotion.\nThe distal extremity of the lower leg, starting at the ankle joint (where the tibia, fibula, and talus meet) and extending to the tips of the toes. It includes the tarsus, metatarsus, and phalanges.\n1. Calcaneal Tuberosity (CT, Heel Bone) 2. First Metatarsal Head (FME, tip of the big toe) 3.Lateral Malleolus (LM) 4. Medial Malleolus (MM)\nX: MM → LM Y: CT → FME Z: Right-hand rule (limits, CT to MM-LM line)\n1. (0, 0, -50)\n1. (50, 0, 50) 2. (-50, 0, 0) 3. (-50, 0, 50)\n\n\n15\n(Left, Foot)\nThe structure found below the ankle joint required for locomotion.\nThe distal extremity of the lower leg, starting at the ankle joint (where the tibia, fibula, and talus meet) and extending to the tips of the toes. It includes the tarsus, metatarsus, and phalanges.\n1. Calcaneal Tuberosity (CT, Heel Bone) 2. First Metatarsal Head (FME, tip of the big toe) 3.Lateral Malleolus (LM) 4. Medial Malleolus (MM)\nX: LM → MM Y: CT → FME Z: Right-hand rule (limits, CT to MM-LM line)\n1. (0, 0, -50)\n1. (50, 0, 50) 2. (-50, 0, 0) 3. (-50, 0, 50)"
  }
]